{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning: 好的，我现在需要解决用户的问题：给出一个使用LangChain的示例，通过OpenAI接口访问DashScope上的DeepSeek模型。首先，我得理解用户的需求。用户可能已经知道LangChain和DashScope，但需要具体的代码示例来整合这两者，尤其是通过OpenAI的API来调用DeepSeek模型。\n",
      "\n",
      "首先，我需要确认DeepSeek模型是否在DashScope平台上可用。假设是的，因为用户提到了这一点。DashScope是阿里云的一个机器学习平台，可能提供了各种模型，包括DeepSeek的。不过，通常OpenAI的接口是用于访问OpenAI自己的模型，比如GPT-3或GPT-4。要访问其他平台的模型，可能需要使用不同的适配器或API客户端。\n",
      "\n",
      "接下来，用户想通过OpenAI的接口来访问，这可能意味着使用OpenAI库中的相同方法，比如使用openai.ChatCompletion.create，但实际请求发送到DashScope的端点。这通常需要修改API的基础URL和API密钥。例如，OpenAI的库允许设置base_url参数，这样可以将请求重定向到不同的服务端点。\n",
      "\n",
      "然后，我需要检查DashScope的文档，看看他们是否提供与OpenAI兼容的API接口。如果他们支持OpenAI格式的请求，那么就可以通过设置适当的base_url和API密钥来实现。例如，可能DashScope有一个特定的端点URL，比如https://dashscope.aliyuncs.com/api/v1，并且使用他们的API密钥，而不是OpenAI的。\n",
      "\n",
      "此外，用户提到使用LangChain，所以需要将这种配置整合到LangChain的组件中，比如使用ChatOpenAI类，但自定义其基础URL和API密钥。这样LangChain就会通过修改后的OpenAI客户端发送请求到DashScope。\n",
      "\n",
      "可能的步骤包括：\n",
      "1. 安装必要的库：openai，langchain，dashscope（如果有的话）。\n",
      "2. 导入所需的模块，比如ChatOpenAI。\n",
      "3. 设置自定义的OpenAI配置，包括base_url和api_key。\n",
      "4. 创建LangChain的ChatOpenAI实例，传入这些参数。\n",
      "5. 构建一个提示模板，调用模型并获取响应。\n",
      "\n",
      "需要注意的是，确保使用的模型名称与DashScope上的DeepSeek模型名称一致，比如\"deepseek-chat\"。另外，可能需要处理不同的响应格式，如果DashScope的响应结构与OpenAI不同，可能需要适配处理。\n",
      "\n",
      "可能的错误点包括：API端点是否正确，模型名称是否正确，API密钥是否有权限，以及响应解析是否正确。需要验证这些步骤，可能需要查阅DashScope的文档，确认他们的兼容性设置。\n",
      "\n",
      "最后，编写示例代码，展示如何配置LangChain的ChatOpenAI来访问DashScope的DeepSeek模型，包括设置环境变量，构建提示，调用模型，并打印结果。\n",
      "Answer: 以下是一个使用LangChain调用DashScope平台DeepSeek模型的示例代码：\n",
      "\n",
      "```python\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.prompts import ChatPromptTemplate\n",
      "from langchain.schema.output_parser import StrOutputParser\n",
      "\n",
      "# 配置DashScope参数（请替换为实际信息）\n",
      "DASHSCOPE_API_KEY = \"your-dashscope-api-key\"\n",
      "DASHSCOPE_BASE_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"  # 确认实际API地址\n",
      "\n",
      "# 创建自定义ChatOpenAI实例\n",
      "chat = ChatOpenAI(\n",
      "    openai_api_base=DASHSCOPE_BASE_URL,\n",
      "    openai_api_key=DASHSCOPE_API_KEY,\n",
      "    model_name=\"deepseek-chat\",  # 根据实际模型名称调整\n",
      "    max_tokens=1024\n",
      ")\n",
      "\n",
      "# 构建对话链\n",
      "prompt = ChatPromptTemplate.from_messages([\n",
      "    (\"system\", \"你是一个有帮助的助手\"),\n",
      "    (\"user\", \"{input}\")\n",
      "])\n",
      "chain = prompt | chat | StrOutputParser()\n",
      "\n",
      "# 调用模型\n",
      "response = chain.invoke({\"input\": \"解释一下量子计算的基本原理\"})\n",
      "print(response)\n",
      "```\n",
      "\n",
      "使用前需要：\n",
      "1. 安装依赖：`pip install langchain-openai`\n",
      "2. 获取DashScope API密钥（前往[阿里云控制台](https://help.aliyun.com/zh/dashscope/)）\n",
      "3. 确认：\n",
      "   - 正确的API基础地址（参考DashScope文档）\n",
      "   - 准确的模型名称（如`deepseek-chat`）\n",
      "   - API密钥是否有访问该模型的权限\n",
      "\n",
      "注意：DeepSeek可能有多个模型版本，建议根据[官方文档](https://help.aliyun.com/zh/dashscope/developer-reference/)选择最新可用版本。\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv('DASHSCOPE_API_KEY'),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"deepseek-r1\",\n",
    "    messages=[\n",
    "        {'role': 'user', 'content': '9.9和9.11谁大'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Reasoning:\", completion.choices[0].message.reasoning_content)\n",
    "print(\"Answer:\", completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供帮助。\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# 配置DashScope参数（请替换为实际信息）\n",
    "DASHSCOPE_API_KEY = os.getenv('DASHSCOPE_API_KEY')\n",
    "DASHSCOPE_BASE_URL = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"  # 确认实际API地址\n",
    "\n",
    "# https://help.aliyun.com/zh/model-studio/developer-reference/deepseek\n",
    "model = \"deepseek-r1\"\n",
    "\n",
    "# 创建自定义ChatOpenAI实例\n",
    "chat = ChatOpenAI(\n",
    "    base_url=DASHSCOPE_BASE_URL,\n",
    "    api_key=DASHSCOPE_API_KEY,\n",
    "    model_name=model, \n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "# 构建对话链\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个好帮手\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain = prompt | chat | StrOutputParser()\n",
    "\n",
    "# 调用模型\n",
    "response = chain.invoke({\"input\": \"你是谁？\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
